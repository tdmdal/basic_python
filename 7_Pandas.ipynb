{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Python Workshop #\n",
    "### Session III - Data Analysis using Pandas ###\n",
    "\n",
    "\n",
    "Pandas library is a central component of the data science toolkit in python. It is built on top of the NumPy package. Hence, NumPy data structures can be replicated in Pandas. Data in pandas is often then fed into other data analysis packages such as SciPy for statistical analysis, Scikit-learn for machine learning and Matplotlib for visualization. \n",
    "\n",
    "The first thing to do is to install Pandas library and import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Importing Data in Pandas__\n",
    "\n",
    "With Pandas we can read data from excel, CSV, JSON and SQL database. Since our data is in csv, we will use the method __.read_csv()__ and assign it to variable \"df\". We can use __.head()__ to view the first 5 rows of our dataset. __.tail()__ outputs the last five rows of the dataset. These functions also accept numbers inside the parenthesis to specify the number of rows to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('companies_by_revenue.csv', skip_blank_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "NOTE: If you have not saved this csv file from before then you can use the code from webscrapping example. You can remove the last two lines, where the data is saved as csv. Instead, you can convert the dictionary-\"mytable_dict\" into Pandas dataframe directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# request data from website and store in a variable\n",
    "website_url = requests.get(\"https://en.wikipedia.org/wiki/List_of_largest_companies_by_revenue\")\n",
    "website_content = website_url.text\n",
    "\n",
    "# convert data to soup object for easy html parsing\n",
    "soup = BeautifulSoup(website_content, \"lxml\")\n",
    "my_table = soup.find( 'table', {'class':'wikitable sortable'} )\n",
    "\n",
    "# parse the table and convert to Python dictionary\n",
    "mytable_dict = { 'Rank':[], 'Name':[], 'Industry':[], 'Revenue':[], 'Profit':[], 'Employees':[], 'Country':[] }\n",
    "\n",
    "for eachrow in my_table('tr')[2:]:\n",
    "    cells = eachrow(['th', 'td'])\n",
    "    \n",
    "    mytable_dict['Rank'].append( cells[0].find(text=True).strip() )\n",
    "    mytable_dict['Name'].append( cells[1].find(text=True).strip() )\n",
    "    mytable_dict['Industry'].append( cells[2].find(text=True).strip() )\n",
    "    mytable_dict['Revenue'].append( cells[3].text )\n",
    "    mytable_dict['Employees'].append( cells[5].find(text=True).strip() )\n",
    "    \n",
    "    mytable_dict['Profit'].append( cells[4].text )\n",
    "    mytable_dict['Country'].append( cells[6].select('.flagicon > a')[0].get('title') )\n",
    "    \n",
    "df = pd.DataFrame(mytable_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now, the variable \"df\" refers to Pandas core data structure called __Pandas dataframe__. The individual columns inside the dataframe is another Pandas core data structure called __Pandas series__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( type(df) )\n",
    "print( type(df['Employees']) )\n",
    "print( type(df['Revenue']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can check the type of the values of each column using __.info()__ method. Note that all columns except \"Rank\" is identified as object. Everything in pandas is an object like in Python and they can be converted to string, integer or float as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Pandas has a useful attribute __.shape__ that outputs the dimension of the dataframe. In our case, the dataset has 50 rows and seven columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Indexing in Pandas__\n",
    "\n",
    "There are many ways to index rows and columns in Pandas. Pandas object have index assigned to them. We can also set our own index using the __.index__ method. Here, we will convert the column \"Rank\" into string and set it as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Rank from type object to string and assign it as index of df\n",
    "df.index = df['Rank'].astype(str)\n",
    "\n",
    "print(df.index)                    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Both Pandas dataframe and pandas series can be indexed using the __index operator [ ]__. We can index by \n",
    "- column name, which has to be inside quotes, or \n",
    "- index number, which is similar to indexing a Python List or\n",
    "- index label, if the assigned index is a string. \n",
    "\n",
    "Index number must be an integer and it starts from 0. Index labels must be written inside quotes as well. \n",
    "\n",
    "In our first example, we will index the column \"Employees\" using column name and assign it to variable \"employees\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = df['Employees']     # indexing \"Employees\" columns from dataframe by using columns name as index\n",
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The variable \"employees\" is now a Pandas series and can be indexed using index number and index label since our index is a string object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( employees[5])            # indexing Pandas series \"employees\" by using index number\n",
    "print( employees['1'])          # indexing Pandas series \"employees\" by using index label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>In order to index rows and columns in the dataframe in a similar manner __.iloc__ or __.loc__ method can be used. Index number is used with .iloc and if the assigned index is a string, the index label is used with .loc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[5])               # indexing dataframe by using iloc and index number\n",
    "print( '\\n-------------------------------\\n')\n",
    "print(df.loc['1'])              # indexing dataframe by using loc and index label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Slicing__\n",
    "\n",
    "Colon __: operator__ can also be used inside the square brackets [ ] to index (or slice) more than one element using index numbers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( employees[0:5])         # indexing Pandas series \"employees\" by using index numbers with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0:3])            # indexing Pandas dataframe by using iloc and index numbers with :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "When indexing for more than one element using column name or index label, __double square brackets__ are required and each string must be separated by comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df[['Name', 'Profit']] )      # indexing dataframe by column names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( employees[['1','2','3','4', '5']] )    # indexing Pandas series by using index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.loc[['1','2','3','4']] )            # indexing Pandas dataframe by using loc and index numbers with ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Both rows and columns can be indexed at once by separating them with comma. Right-hand side of the comma is for rows and left-hand side is for columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['1','2','3'], ['Name', 'Country']]   # Select both rows and columns at the same time used index label and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:4, :]                             # Select all columns of second to fourth rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Filtering__\n",
    "\n",
    "Dataframe can also be indexed using booleans. With boolean indexing, we must pass an array or series of True False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df['Country'] == 'United States'\n",
    "\n",
    "print( list(idx) )\n",
    "df.loc[idx, ['Name', 'Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Industry'] == 'Retail') | (df['Industry'] == 'Commodities'), ['Name', 'Rank']]   # OR operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Employees'] > 1000000) & (df['Employees'] <= 2000000), ['Name', 'Rank']]        # AND operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Changing Data Types__\n",
    "\n",
    "The method __.str.replace__ can be used to replace any character from a string. Then the method __astype__ can be used to convert numeric strings into integer or float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employees'] = df['Employees'].str.replace(',', '')\n",
    "df['Employees'] = df['Employees'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Employees'] > 1000000) & (df['Employees'] <= 2000000), ['Name', 'Rank']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Multiple strings can be replaced at once and string replacement and type conversion steps can also be combined together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Revenue'] = df['Revenue'].str.replace('$','').str.replace(',','')\n",
    "df['Profit'] = df['Profit'].str.replace('$','').str.replace(',','')\n",
    "df[['Revenue','Profit']] = df[['Revenue','Profit']].apply(pd.to_numeric)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Math operations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_employee = df['Employees'].max()\n",
    "min_employee = df['Employees'].min()\n",
    "\n",
    "max_revenue = df['Revenue'].max()\n",
    "min_revenue = df['Revenue'].min()\n",
    "\n",
    "print(max_employee, min_employee, max_revenue, min_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nemp = df['Employees'].mean()\n",
    "print(type(avg_nemp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Column Names__\n",
    "\n",
    "The attribute __.columns__ lists all the column names of the dataframe. It can also be used to assign column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower() for col in df]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Dropping columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['rank'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Resetting Index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Creating a new column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rev_per_emp'] = df['revenue'] / df['employees']\n",
    "new_df = df.sort_values('rev_per_emp', ascending=False)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.round({\"rev_per_emp\":2}) \n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Missing Values__\n",
    "\n",
    "We do not have null values in our dataset. However, its a common issue when working with data. We can check for null values using __.isnull()__ method.\n",
    "\n",
    "To delete any rows with at least a single null value, we can use__.dropna()__ method. This will return a new dataframe without altering the original one unless we set __inplace=True__ argument inside parenthesis. To drop columns with missing values instead, we have to set __axis=1__ inside parenthesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Aggregating and Grouping in Pandas__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__.value_counts()__ is a popular method to get frequency of all values in a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__.groupby()__ method can be used to get frequencies and other mathematical operations based on one or more columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country = df.groupby(['country'])['revenue']\n",
    "country_avg =  group_by_country.mean()\n",
    "\n",
    "print(country_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_country = df.groupby(['industry', 'country'])['employees']\n",
    "max_employee =  group_by_country.max()\n",
    "\n",
    "print(max_employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Applying Functions to Pandas column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region(country):\n",
    "\n",
    "    Asia = ['China', 'Japan', 'Singapore', 'South Korea', 'Taiwan', 'Russia']\n",
    "    Europe = ['Switzerland', 'United Kingdom', 'Netherlands', 'Italy', 'Germany', 'France']\n",
    "    North_America = ['United States']\n",
    "\n",
    "    if country in Asia:\n",
    "        Region = 'Asia'\n",
    "    elif country in Europe:\n",
    "        Region = 'Europe'\n",
    "    elif country in North_America:\n",
    "        Region = 'North America'\n",
    "    else:\n",
    "        Region = 'Nan'\n",
    "        \n",
    "    return Region\n",
    "\n",
    "df['region'] = df['country'].apply(region)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Visualizing in Pandas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['industry'].value_counts().sort_values(ascending=False).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "df.groupby('country').revenue.mean().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=45, fontsize='x-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "chart = sns.catplot(\n",
    "    data=df[df['industry'].isin(['Financials', 'Oil and gas', 'Automotive'])],\n",
    "    x='region',\n",
    "    kind='count',\n",
    "    palette='Set1',\n",
    "    col='industry',\n",
    "    aspect=1,\n",
    ")\n",
    "chart.set_xticklabels(rotation=65, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
